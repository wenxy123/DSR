{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce672f7e-b062-484b-adfb-5049a4181eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split, SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.spatial import cKDTree\n",
    "from scipy.ndimage import zoom  # For resampling\n",
    "import math\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.linalg import vector_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158ded30-7ff4-4bc8-8eb7-33c3ffe3e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/data/jianglab1/xiaoyi/code/DSR_code/DSR/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "408dbfa2-0657-4220-82fc-13a9fbc8e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DSR_pretrain import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e34221f0-c2ca-431f-b76a-a47bc248d2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4da03a55-75b0-4b11-81dc-6f3e1519db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = torch.load('Data/train_input_100.pt')\n",
    "train_target = torch.load('Data/train_input_100.pt')\n",
    "\n",
    "valid_input = torch.load('Data/valid_input_100.pt')\n",
    "valid_target = torch.load('Data/valid_input_100.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdde8186-a36d-43db-9b2d-20a0af440fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 3, 16, 16, 16])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e354155-8e69-4b09-8260-eefeade18ab7",
   "metadata": {},
   "source": [
    "# Pre-train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4bcac16-1fa4-487b-a7e6-b82fd0646c03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available, running on GPU.\n",
      "\n",
      "Batch is larger than half of the sample size. Training based on full-batch gradient descent.\n",
      "[Epoch 1 (0%)] energy-loss: 28.1095,  E(|Y-Yhat|): 57.7704,  E(|Yhat-Yhat'|): 59.3219\n",
      "[Epoch 2 (5%)] energy-loss: 27.5950,  E(|Y-Yhat|): 57.2429,  E(|Yhat-Yhat'|): 59.2958\n",
      "[Epoch 3 (10%)] energy-loss: 27.0119,  E(|Y-Yhat|): 56.6922,  E(|Yhat-Yhat'|): 59.3607\n",
      "[Epoch 4 (15%)] energy-loss: 26.5395,  E(|Y-Yhat|): 56.1564,  E(|Yhat-Yhat'|): 59.2338\n",
      "[Epoch 5 (20%)] energy-loss: 26.1269,  E(|Y-Yhat|): 55.5828,  E(|Yhat-Yhat'|): 58.9117\n",
      "[Epoch 6 (25%)] energy-loss: 25.7254,  E(|Y-Yhat|): 55.1908,  E(|Yhat-Yhat'|): 58.9309\n",
      "[Epoch 7 (30%)] energy-loss: 25.4570,  E(|Y-Yhat|): 54.8541,  E(|Yhat-Yhat'|): 58.7941\n",
      "[Epoch 8 (35%)] energy-loss: 25.0684,  E(|Y-Yhat|): 54.6128,  E(|Yhat-Yhat'|): 59.0888\n",
      "[Epoch 9 (40%)] energy-loss: 24.6602,  E(|Y-Yhat|): 54.2311,  E(|Yhat-Yhat'|): 59.1419\n",
      "[Epoch 10 (45%)] energy-loss: 24.4101,  E(|Y-Yhat|): 53.8321,  E(|Yhat-Yhat'|): 58.8441\n",
      "[Epoch 11 (50%)] energy-loss: 23.9773,  E(|Y-Yhat|): 53.6143,  E(|Yhat-Yhat'|): 59.2740\n",
      "[Epoch 12 (55%)] energy-loss: 23.4731,  E(|Y-Yhat|): 53.3051,  E(|Yhat-Yhat'|): 59.6641\n",
      "[Epoch 13 (60%)] energy-loss: 23.3777,  E(|Y-Yhat|): 53.0882,  E(|Yhat-Yhat'|): 59.4210\n",
      "[Epoch 14 (65%)] energy-loss: 23.1153,  E(|Y-Yhat|): 52.8305,  E(|Yhat-Yhat'|): 59.4304\n",
      "[Epoch 15 (70%)] energy-loss: 22.9203,  E(|Y-Yhat|): 52.8389,  E(|Yhat-Yhat'|): 59.8370\n",
      "[Epoch 16 (75%)] energy-loss: 22.4491,  E(|Y-Yhat|): 52.4864,  E(|Yhat-Yhat'|): 60.0745\n",
      "[Epoch 17 (80%)] energy-loss: 22.3444,  E(|Y-Yhat|): 52.2044,  E(|Yhat-Yhat'|): 59.7202\n",
      "[Epoch 18 (85%)] energy-loss: 22.0039,  E(|Y-Yhat|): 51.8893,  E(|Yhat-Yhat'|): 59.7708\n",
      "[Epoch 19 (90%)] energy-loss: 21.7811,  E(|Y-Yhat|): 51.8295,  E(|Yhat-Yhat'|): 60.0969\n",
      "[Epoch 20 (95%)] energy-loss: 21.7241,  E(|Y-Yhat|): 51.8346,  E(|Yhat-Yhat'|): 60.2209\n",
      "\n",
      "Validation loss on the original (non-standardized) scale:\n",
      "\tEnergy-loss: 29.1911,  E(|Y-Yhat|): 44.7358,  E(|Yhat-Yhat'|): 31.0894\n",
      "\n",
      "Prediction-loss E(|Y-Yhat|) and variance-loss E(|Yhat-Yhat'|) should ideally be equally large\n",
      "-- consider training for more epochs or adjusting hyperparameters if there is a mismatch \n"
     ]
    }
   ],
   "source": [
    "beta = 1\n",
    "\n",
    "DSR = DSR_train(train_input, train_target, valid_input, valid_target, lr = 1e-4, num_epochs=20, batch_size=256, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2199729e-98cd-49c9-a21d-a00d03ba73db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: DSR_unet_model_pretrain.pth\n"
     ]
    }
   ],
   "source": [
    "DSR.save_model(\"DSR_unet_model_pretrain.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b1c89-c097-435c-b6cc-817c31bad111",
   "metadata": {},
   "source": [
    "## Evaluate pre-train model on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "453b589b-f8e1-47dc-be39-1f532df68735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "def load_model(model, model_path, device):\n",
    "    # Load the model's state dict from the saved file\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8be843bc-afa6-4fc6-b117-c4fe5c2c47b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet3D(\n",
       "  (encoder1): Sequential(\n",
       "    (0): Conv3d(3, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout3d(p=0.2, inplace=False)\n",
       "    (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout3d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (pool1): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (encoder2): Sequential(\n",
       "    (0): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout3d(p=0.2, inplace=False)\n",
       "    (4): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout3d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (pool2): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (encoder3): Sequential(\n",
       "    (0): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout3d(p=0.2, inplace=False)\n",
       "    (4): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (5): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout3d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (bottleneck): Sequential(\n",
       "    (0): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout3d(p=0.2, inplace=False)\n",
       "    (4): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (5): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout3d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (upconv3): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "  (decoder3): Sequential(\n",
       "    (0): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout3d(p=0.2, inplace=False)\n",
       "    (4): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (5): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout3d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (upconv2): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "  (decoder2): Sequential(\n",
       "    (0): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout3d(p=0.2, inplace=False)\n",
       "    (4): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (5): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout3d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (upconv1): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "  (decoder1): Sequential(\n",
       "    (0): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout3d(p=0.2, inplace=False)\n",
       "    (4): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "    (5): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Dropout3d(p=0.2, inplace=False)\n",
       "  )\n",
       "  (conv): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('DSR_unet_model_pretrain.pth')\n",
    "DSR = UNet3D(in_channels=3, out_channels=3)\n",
    "DSR.load_state_dict(checkpoint['model_state_dict'])\n",
    "DSR.to(device)\n",
    "DSR.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b2dd507-f95e-4968-8107-a52960af56a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### DSR prediction\n",
    "batch_size = 32\n",
    "sigma_t = 0.1\n",
    "n_samples = valid_input.shape[0]\n",
    "\n",
    "num_runs = 200\n",
    "DSR_predictions = []\n",
    "\n",
    "# Use torch.no_grad() to prevent storing gradients during inference.\n",
    "for start_idx in range(0, n_samples, batch_size):\n",
    "    end_idx = min(start_idx + batch_size, n_samples)\n",
    "    \n",
    "    batch = valid_input[start_idx:end_idx].to(device)\n",
    "    target = valid_target[start_idx:end_idx].to(device)\n",
    "    batch_sum = torch.zeros_like(target).to(device)\n",
    "\n",
    "    # Loop over the number of runs to compute predictions\n",
    "    for run in range(num_runs):\n",
    "        # Generate noise and add it to the input batch\n",
    "        epsilon_t = torch.randn_like(batch) * (sigma_t ** 0.5)\n",
    "        input_batch = batch + epsilon_t\n",
    "        DSR_preds = DSR(input_batch)\n",
    "        batch_sum += DSR_preds.detach()\n",
    "\n",
    "    # Compute the average prediction for this batch\n",
    "    batch_mean = batch_sum / num_runs\n",
    "    DSR_predictions.append(batch_mean)\n",
    "        \n",
    "# Concatenate all batch predictions into one final prediction tensor\n",
    "DSR_predictions = torch.cat(DSR_predictions, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2a78d5c-1c16-485e-b80b-f5cfffcd4891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 3, 16, 16, 16])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSR_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42aec0f-b185-4943-bea6-186e457bb08c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
